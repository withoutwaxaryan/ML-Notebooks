{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "In this lab, we will be exploring how to preprocess tweets for sentiment analysis. We will provide a function for preprocessing tweets during this week's assignment, but it is still good to know what is going on under the hood. By the end of this lecture, you will see how to use the NLTK package to perform a preprocessing pipeline for Twitter datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "You will be doing sentiment analysis on tweets in the first two weeks of this course. To help with that, we will be using the Natural Language Toolkit (NLTK) package, an open-source Python library for natural language processing. It has modules for collecting, handling, and processing Twitter data, and you will be acquainted with them as we move along the course.\n",
    "\n",
    "For this exercise, we will use a Twitter dataset that comes with NLTK. This dataset has been manually annotated and serves to establish baselines for models quickly. Let us import them now as well as a few other libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  # python library for nlp\n",
    "from nltk.corpus import twitter_samples # dataset\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Twitter dataset\n",
    "The sample dataset from NLTK is separated into positive and negative tweets. It contains 5000 positive tweets and 5000 negative tweets exactly. The exact match between these classes is not a coincidence. The intention is to have a balanced dataset. That does not reflect the real distributions of positive and negative classes in live Twitter streams. It is just because balanced datasets simplify the design of most computational methods that are required for sentiment analysis. However, it is better to be aware that this balance of classes is artificial.\n",
    "\n",
    "The dataset is already downloaded in the Coursera workspace. In a local computer however, you can download the data by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/aryan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 json files : 1 containing all samples, and 1 each for positive & negative samples respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the text fields of the positive and negative tweets by using the module's `strings()` method like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll print a report with the number of positive and negative tweets. It is also essential to know the data structure of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Positive Tweets:  5000\n",
      "No. of Negative Tweets:  5000\n",
      "Type of positive samples:  <class 'list'>\n",
      "Type of negative samples:  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('No. of Positive Tweets: ', len(all_positive_tweets))\n",
    "print('No. of Negative Tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('Type of positive samples: ', type(all_positive_tweets))\n",
    "print('Type of negative samples: ', type(all_negative_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is stored in a list and as you might expect, individual tweets are stored as strings.\n",
    "\n",
    "You can make a more visually appealing report by using Matplotlib's pyplot library. Let us see how to create a pie chart to show the same information as above. This simple snippet will serve you in future visualizations of this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAEeCAYAAAAkWrYyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAngklEQVR4nO3deXzcdYH/8ddnjhyTY9L0bmkbaAOUq4VSwiEotyegXAq7C7rioqzH6h5dcXEUZdldV1lXRFFXBP1BQREjpaUISMsVetGDQppCC/S+c02SuT6/P77flpimbdJm5jsz3/fz8ZhHm8kc70nT93zm8/kexlqLiIhkV8DrACIifqCyFRHJAZWtiEgOqGxFRHJAZSsikgMqWxGRHFDZiojkgMpWRCQHVLYiIjmgshURyQGVrYhIDqhsRURyQGUrIpIDKlsRkRxQ2YqI5IDKVkQkB1S2IiI5oLIVEckBla2ISA6obEVEckBlKyKSAypbEZEcUNmKiOSAylZEJAdUtiIiOaCyFRHJAZWtiEgOqGxFRHJAZSsikgMqWxGRHFDZiojkgMpWRCQHVLYiIjkQ8jqA+FPdrDm1wDhgbK8/9/59GBDG+f0MA6FY6Fdv3Bh68ngg5V6S7qUV2ARsdi+bev25k1irzeHLEjkgla1kTd2sOcOB04EZwDRgAk6ZjgFKB/NYJba7Ezh1kBESxKJbcYp3A7ACWAIsIda6ZZCPJXJEVLYyJPoU697LpKF6/Lb2zinUDvpuJTgFPwFoAK7c951YdCN7i1cFLDmgspXDUjdrzkTgMuB8hrhY+xMMmO4hfsjx7uWyfde8V8B/Bv5IrHXtED+n+JjKVgakbtYcgzNyvQz4GM60QLHpXcDfJxZ9Hfgj0Ai8RKw142U4KWwqWzmgullzyoALgcustR81xozzOlOOTXUv/wxsJxadg1O884m1dnqaTAqOylb+Qt2sOWHg48CnrLUXG2MqAIwx3gbz3kjgRvfSTSz6LDAbmE2sdainOKQIqWwFgLpZc44C/s5ae5MxZjSoYA+iDPiQe/k+segvgXuItb7pbSzJZypbH3PnYS+y1t4CfNQYE1TBDlot8DXgq8Si84EfA49rflf6Utn6UN2sOTXAp63NfMGYwBQV7JAwwKXu5W1i0XuBnxNr3eZtLMkXKlsfqZs1p95a+y/AdcaYcmO0t3aWTAK+C3yTWPR3wJ3EWld4nEk8prL1gbpZc8bZdOp2AsEbjDFBr/P4SAnwKeBaYtEHgX8j1rrO40ziEZVtEaubNacmk+y5zQTDt5hgqMTrPD4WAK4HrnanF27X9IL/qGyLUN2sOeU2lfgqgeCsQLi00us8sk8J8PfAjcSi3we+R6y13eNMkiMq2yJSN2tO0KaTN4G53YRKRnidRw6oErgN+Dyx6HdxNhtLeJxJskwrJEVi0j/94aM2lXzTBMP3mGBIRVsYRgJ3AWuIRa/1OItkmUa2BW7i1x6tsenkr4JllZcd+taSpyYBDxGLfhK4mVjrVq8DydDTyLaAjb/5F38NvK2iLRpXAKuJRa/zOogMPY1sC9BRt9xfizEPhWvGXOx1FhlytcBviEWvRqPcoqKRbYEZf/Mv/jpQVrkuVFmroi1uV6BRblHRyLZAaDTrSxrlFhGNbAvA+Jt+epVGs752Bc4o9wqPc8gRUNnmsUh9Q3Dcp//37tCwcQ8HwqXVXucRT9UCjxKLfpNYVEcOKkAq2zwVPeeTo2ref+NLJaOP+YIJBPSfS8A5slgMeJhYtMLjLDJIKts8NPyDX5xRNf3Dy0pGTJzpdRbJS1cBLxCLZvUkmzK0VLZ5ZuQV//pXFVPPey5UNdxv5/uSwZkGLCIWfZ/XQWRgVLZ5IlLfEBx97e3/Hak/85eB0og+IspAjASeIRa9yesgcmja9CsPVJx4fkX0nOt+VzpmyqVeZ5GCEwbuJRadBnyFWGvK60DSP41sPVZ1+sfG15zzqcUqWjlCtwBziEUjXgeR/qlsPVR16odOqZ5x2Qvh2vHHe51FisIlwFxi0Sqvg8j+VLYeqTr1Q+dVn3Hl3PCwcVpRlqF0HjCfWDTqdRD5SypbD1TN+OjF0TOvnh0eNlZbHEg2nAk8TSxa63UQeY/KNseqpn/w0ugZVz4Qio4e43UWKWozcAp3mNdBxKGyzZFIfYOpPPmiD1efefV9oeio0V7nEV+YDswjFtWu3nlAZZsjpiRySfSsa+4N14zRiFZy6QzgCe3e6z2VbQ5UnHDeBdGzrr03XDt+vNdZxJfOAf5ILFrudRA/U9lmWaS+4ezqGZffXTJiwkSvs4ivnQ/80usQfqayzaJIfcPMihM+8L3S8cdrO1rJB9cSi37d6xB+pbLNkkh9w+TS8SfEIse9r8HrLCK9fIdYVCcI9YDKNgsi9Q3DQ9HRt1bN+Nj5JhDQz1jyiQF+TSx6otdB/EZFMMQi9Q1lpiTyD9Gzr70sEC7VgoTkoyqgUTs95JbKdghF6hsCYP4metY11wcjNcO9ziNyEMcAjxCL6sh/OaKyHVofrDrtI18oGTGxzusgIgNwAfADr0P4hcp2iETqG04pnzzzn8rqTp3mdRaRQfh7YtHPeh3CD1S2QyBS3zA+VDPmXytPvvgcY3RuRik4dxOLTvc6RLFT2R6hSH1DFfDl6pkfP9cEQ2Gv84gchhLgPmJR/f5mkcr2CETqGwxwQ8VJF50Tqh6pXXGlkE0DtMNDFqlsj8zMUHT0BZEpZ+iU41IMbtV0QvaobA9TpL5hGHBjdcOVp2v6QIpEGE0nZI3K9jC40wfXV5x80bRQ1YgJXucRGULTgFu9DlGMVLaHx5k+mKzpAylKX9d0wtBT2Q6Spg/EBzSdkAUq20HQ9IH4iKYThpjKdnBmBsqrz41MPuN0r4OI5MDXiUWP9jpEsVDZDlCkvqEGuLHq1A8fY4KhEq/ziORAGLjd6xDFQmU7cJ8IRUcPKxk95VSvg4jk0HXEojrexxBQ2Q5ApL7hKODcyukfmmoCgaDXeURyyAB3eB2iGKhsD8FdFLsyPHJSJDx8wile5xHxwIeJRc/zOkShU9ke2mTg1MpTLp1mdEgv8a87vQ5Q6FS2B+GOaq8pPeqEqnDNmOO8ziPiobOIRS/3OkQhU9ke3EnAsZUnXqBNvUTgDmJRdcZh0g/uACL1DUHg2vLJM2uClbUTvc4jkgdOAP7G6xCFSmV7YDOACZHjzmnwOohIHokRi2qLnMOgsu1HpL6hBLi2dMLJJcHy6jFe5xHJI5OAy7wOUYhUtv1rAIZHppxxktdBRPLQF7wOUIhUtn1E6hsCwEeClbXxUM3YqV7nEclDFxKLHut1iEKjst3fFGB0xdT3H6e9xUT6ZYDPex2i0Khs93chxvSUjJkyw+sgInnsRmLRiNchConKthf3wOAzI/Vn1QRKyqNe5xHJYzXAp7wOUUhUtn/pTMCWTZqmnRhEDk0LZYOgsnVF6htCwAfDtUelglUjJnudR6QAnEYsqu3QB0hl+54TgerI8eeerOPNiAyYRrcDpLJ9z6UY01EycpIOlCwycNcQi1Z4HaIQqGyBSH3DWGBq2cRTKkyoRCusIgNXBlzidYhCoLJ1NACZ0vFTdRhFkcHT7rsD4PuydY9ZezawMzxsvMpWZPA+okMvHpp+QDAaGBEeWVceKKsY7nUYkQI0EjjL6xD5TmULUwHKJp6iUa3I4dNUwiGobJ0phLbwiIkqW5HDp7I9BF+XbaS+oRqYHIjU9AQrhk3wOo9IATueWHSK1yHyma/LFjgWoPyYGfU6c67IEdPo9iD8XrZnAN0lo47WFILIkVPZHoRvy9Y99c10jNkVqh6lYyGIHLn3EYtWeR0iX/m2bIHJQLBk5NE1Jhgq9TqMSBEIAqd6HSJf+blsTwIy4ZF147wOIlJEdND9A/Bz2Z4ItIVqxoz1OohIEVHZHoAvyzZS3xAGjgI6g5W1GtmKDB0deP8AfFm2OLvoGoyxwfLqMV6HESkix2qRrH9+LduxACUjjx5ugqESr8OIFBGDFsn65deyPQZIa3FMJCs0b9sPv5btVKBdi2MiWaGy7YfvytZdHJuAFsdEskWLZP3wXdniLI6hxTGRrNEiWT/8WLZjAYJVIyq0OCaSFQao8zpEvvFj2R4DpENVI/TOK5I9Wg/pw49lOwGIByI1lV4HESliWg/pw49lOxxIBMurNbIVyR6NbPvwVdm6Z9IdBvQEyipVtiLZo5FtH74qW6AEKAXSgdKIylYkezSy7cNvZVsFZABMSURztiLZo7Ltw49lawECJWUa2Ypkj6YR+vBb2VbibAOICZeqbEWyRyPbPvxWtlU4h1Y0JlRS4XUYkSJWSixa63WIfOK3sh0G2GDFsHJjAn577SK5NtrrAPkkdKgbGGPSwEr3tq8DN1hr4wN9AmPMOOCH1tqrjDHTgXHW2ifc710GnGCtvfNwwh+GkUDChEoO+bqzYcM9nyFQUg6BACYQZOwNd5HuamfHH/6DVNtWQtWjGXHFLIJl+6/ddb21hF1P3wuZDJXTLiF65tUA7P7zL+l6awklo45mxEe/BkDHqmfIdLdTffrlOX19MnB1d7VTVWoIGggFYPHnKtnVZbn2t3HW77HU1RgevirCsHKz333nrU3x5XndpDOWz55Wwqz3Oecr/Zenupm7NsX0MUHu/3g5AA8sT7Cry/LlMz05p+mgntQYY4HvW2u/5n79j0CltTY2lKGMMV+31t7R6+sXrbVnD+Vz9Gcgo7sua+10a+1JQAK4eTBPYK3dZK29yv1yOvDhXt9rzGHRgrtDA4GQZ6Pa0Z+6g3Gf/l/G3nAXAG0vP0JZ3TTGf+5nlNVNo+3lR/a7j82k2fXUPYy6+luM++yP6Vz9HIkd75Dp6aRn4+uM+8yPsDZDYvt6MskeOlf9iapTP5LjVyaD9ewNEV69uZLFn3PeXO98vocLjw7R8sVKLjw6xJ3P9+x3n3TGcssTXcy9PsLqWyp5cFWS1dvTtHZbXtyQZsXnK0lby8qtabqSlvuWJ/nCTM8OATLYQU0P8AljzIhshOnl672/yEXRwuCnERYCU4wxtcaYx4wxK4wxLxtjTgEwxrzfGPOqe1lmjKkyxtQZY1YZY0qAbwPXut+/1hhzozHmR8aYqDFmvTEm4D5OxBjzrjEmbIyZbIyZZ4xZYoxZaIw53r3N1e7jLjfGLBhg/hIgbQLBvJlCiK9touKkCwGoOOlC4i0v73ebxOY1hGrGEq4ZgwmGqZh6Hl0tLwMGm05hrcWmEphAkLZXHqVqxmWYoCeDdzkCf2hOccO0MAA3TAvzWHNqv9u8sjHNlNoAxwwLUBI0fPLEMH94I0XAQCJtsdbSlYRwEP7rxQRfOqOEcHD/0XGODPaXMAXcC/xD328YY0YaY35njFnkXs7pdf1TxpilxpifGmPe3lvWbkctMca8Zoz5nHvdnUC520G/ca/rcP+cbYz5cK/nvM8Yc6UxJmiM+S/3eVcYY/7O/f5YY8wC97FWGWPOPdiLG3DpGGNCwIdwphS+BSyz1p6C8y5xv3uzfwRusdZOB84Fuvbe31qbAG4DZrsj5dm9vtcKLAfe7171MeBJa20S54f/RWvtDPfxf+ze5jbgUmvtNOCyAb6MIGDxqmyNYdvDt7H5vi/T/uo8ANKdewhVOusIocpaMp179rtbqn0noeqR+74OVo0g3bGTQGmEyHFns/m+LxGKjsaUVpDYvIZI/Zk5eTly+IyBSx6IM+PeDu5dkgBga0eGsVXOr+bYqgDbOjP73W9ju2VC9Xu/vkdVGza2Z6gqNVw5NcypP+3k6JoA0VLDok1pLj8+nJsX1L/Dece/G7jeGBPtc/3/AD+w1s4ErgR+7l7/TeAZa+1pwO+Bib3u8xm3N04HvmSMGW6tncV7n9av7/McDwHXAriDwwuBJ4C/BVrd554J3GSMORq4DqenpgPTgFcP9sIG8sMoN8bsfZCFwC+AJvcFY619xhgz3P3hvAB8333HeNRau8GYAb+rznZf6LPAJ4EfG2MqgbOBR3o9zt55oBeA+4wxDwOPDvA5goA1AW8Wx8Zc/5+EqoaT7tzD1tnfIDz8qCN4NOfnEW24imiDM0uzc+4PqTn3r2hf/iTd65YRHlVHzdmfHILkMtRe+EwF49xCvfiBOMePGNivpLX7X7f3f8Y/n1PKP5/j/Pf4bGMX3/5AKT9fmmD+mylOGR3kG+flfN520E1vrW0zxtwPfIlegzXgIuCEXj1QbYypAt4HfNy97zxjzO5e9/mSMebj7t8nAPXAzoM8/Vzgh8aYUuCDwAJrbZcx5hLgFGPM3unQqPtYi4D/M8aEgcesta8e7LUNZs52urX2i+4Itb8Gte7862eBcuDlvR/5B6gR+JAxphbntBrPuPn29Hr+6dbaqe6T3Qx8A+eH+KoxZvgAnsMZ2XokVOVEDFbUEDn2LHo2rSFYUUOqYxcAqY5dBCpq+r1fqm37vq/T7TsIVv7lVjWJrW86tx02ns5VzzDyilkkt79NctfGLL0aORLj3BHsqIoAHz8+xCsb04yuDLC53RnNbm7PMKpi//+eR1Ub3m17b8S7oc3ue6y9lm1OA3Ds8AD3L0/y8NURVm1L07Izna2XcyCH+3/tLpzRZO/NMwPAWb16YLy1tp3+uwhjzAdwCvos99PvMqDsoGGt7Qb+DFyKM/B7aO/D4Xy63vvcR1tr51trFwDnARuBB4wxf3Owxz/cEd4C4PpeL2qH+4402Vq70lr7H8BioG/ZtuNs67ofa20H8ArOx4XHrbVpa20bsM4Yc7X7XMYYM839+2RrbZO19jZgB07pHkoQsDaT2f/zWZZlEt1keuL7/t69bhklIycRmdJA56qnAehc9TSRKQ373bdk7LGkdm8iuWcLNp2k8/UFlPe53Z6Fvyb6vushkwLrvjwTwKb2X2QRb3UmLO09dt/f57+Z5qRRQS47NsSvlicB+NXyJJcft/8Hz5njg7TszLBud4ZE2vLQa0ku63O7f3u2h2+fX0oyA2m37gIG4snsvq5+7D/pPADW2l3AwziFu9d84O/3fuFu2QTwPHCNe90lOJt3gjP63G2tjbuDvt5za0l3NNqfh4BP40yDPule9yTw+b33McYca4ypMMZMArZZa3+G84n/tIO9rsNdRYkBvzTGrADiwA3u9V8xxpwPpIHVOMPy3nuSPAvMcqcl/r2fx50NPAJ8oNd11wP3GGO+gfOx5CGc+d3/MsbU47zrPO1edyjOu2A6lfO3+HR8D9sf/Y7zRSZDxQnvp/yYGZSMrWfHH+6kY8V8QtUjGXH5vwLOPO3OeT9k9NXfwgSC1F58M9sevg1shsqTL6Zk5KR9jx1f8xIlY+r3jZxLxx3Ppl/cQnhUHSWjjsn1S5VD2Npp+fhs5403lYHrTgrzwSkhZo4LcM1vu/jFsiQTo4ZHro4AsKk9w2cbu3ni+gihgOFHHy7j0l/HSVvLZ6aXcOKo4L7HfuyNJDPHBfeNds86KsjJ93RwyugA08YE9w+TXUdS7/9Nr3LFmVa42+2cEM6A72ac9aMHjTHXAs8Bm3EGdfOAm93bNwO9V57vBVYYY5b2M287H2cNqtH9FA/O/HAdsNQ48xjbgStweuqfjDFJoAM46MjW2P4mgYpUpL7hdqAsNGx8qPaCv/2K13lk4G7t/sH6m2oW1XmdQwbldGKtS7L5BO78atpamzLGnAXc4y5Y5R2/bR+UAgyZdM6nEUR86LCmEQZpIvCwu9loArgpB895WPxWtmnAZJJduZ+9EvGfAe9peristS3Aqdl+nqGQNxv354hTtvHWbpvJ5HzeVsRntngdIJ/4rWyTuK/ZpnraPc4iUsw6iLXq/1gvfivb3Ti77GKT3R0eZxEpZpu9DpBv/Fa223HLNpPo1ruuSPZs8jpAvvFb2e7C2bEBm4irbEWyRyPbPvxWtu24J3zM9HSqbEWyR2Xbh9/KtgN3f+1Md4fmbEWyR9MIffitbPcduCIdb9PIViR7NLLtw79l27lbZSuSPRrZ9uG3su3G2YUwkGrbrrIVyR6NbPvwVdnGW5ossAcozcT3dNlUIuu7E4r4UAJ4y+sQ+cZXZevaibutbTreqndfkaG3ilhr4tA38xc/lu0mnDNJkG7fqXklkaGX1cMqFio/lu1a3JFtcs9mjWxFhp7Kth9+LNvNuNvaJra+pZGtyNBT2fbDr2VrAJPavbFVi2QiQyoBrPA6RD7yXdnGW5p6cOZtI6BFMpEhpsWxA/Bd2brW4J7lV4tkIkNKUwgH4NeybUGLZCLZoLI9AL+WrRbJRLJDZXsAfi7bfYtkmWSPjgAmcuTiaHHsgHxZtn0XyVJ7trR4m0ikKPxJi2MH5suydb0BVAMktrQ0e5xFpBg0eh0gn/m5bFcCYYCudUvftJl0yuM8IgXLWpsB/uh1jnzm57JtwTlFTsAmu1Pp9h06SpHIYTLGvEKsdZvXOfKZb8s23tIUB14HhgEktq3TVILI4dMUwiH4tmxdLwEVAF3rljZbaz2OI1KwVLaH4PeybWbvaXLad3Rm4q0bPc4jUnCstW8Ra33N6xz5ztdlG29p2glswN11N7nzXU0liAySMUYLYwPg67J1vYg7b9v97iqVrcjgaQphAFS2sO/jT2JLy7ZMT3yXl2FECom1diewwOschUBl60wjdABlAD1bWpZ6G0ekcBhj7iPWqm3UB8D3ZRtvacrgTCUMB4i/sXCZzWTS3qYSyX/W2XznHq9zFArfl62rCXdvsnTHrnhq9yatrIocgoWniLW+6XWOQqGydawH3gFqALreWrTIyzAihSBgzN1eZygkKlsg3tJkgTlAFKD7nZUb0l1tW7xNJZK/0hn7LvC41zkKicr2PcuBHtwzOPRseF2jW5EDCAbMT4i1ZrzOUUhUtq54S1M38CdgFEDnGwtW2nSyx9tUIvnHWpsEfu51jkKjsv1LzwMhwNhEVzKx451XPc4jkncs/E5H+Bo8lW0v8ZamLcAq9m4G1vyiphJE+tDC2OFR2e5vPu6RwJLb1+1MtW5b63EekbyRztilxFqf9zpHIVLZ7m810AqUA3Su/vPTOvSiiCMYMLO8zlCoVLZ9xFuaUsBc3IWynk1vbEnt3rTK21Qi3utO2ReItT7ldY5CpbLt3/NAF+7xEjpWPPWMtRlt5iK+Fg7wFa8zFDKVbT/iLU2dwG+BMQDJne/sTm5/WweoEd+KJ+2c4LfbFnudo5CpbA/seWA3UAnQvnzeczaTTnobSST3MtamI2HzVa9zFDqV7QHEW5oSwGxgBEC6bXtHYnPLy96mEsm97hT/j1jrGq9zFDqV7cEtAjbhHqCmffncF2wq2eVpIpEcSmdsIhLWFghDQWV7EPGWpjTwEO5pczJd7T3dG17TNobiGz1p7iHWusnrHMVAZXtoK4EW3OmEjhVPvpJJdLV6G0kk+1IZ2xEJm295naNYqGwPwT384mycM/Aam+xJdb6+QIeWk6LXneIfiLXu9jpHsVDZDsxaYBkwGqBrbdNaHaRGitmuLvtS5R1tOrLXEFLZDkCv0W0Y93i3ba/8bl4m2d3uaTCRLOhJ2e62HvtJr3MUG5XtAMVbmjbjFO54cBbLOlc/1+htKpGht7nD3lp3V/s7XucoNirbwXkaWIN73ARNJ0ix2daZWVx3V/v3vc5RjFS2g+BuCvZLoBRNJ0iR6UnZ7niSK73OUaxUtoMUb2nahKYTpAht7rBf1/RB9qhsD4+mE6SobOvMLKq7q/0HXucoZirbw3DA6QTt7CAFqDtl4/EkV3mdo9ipbA9Tf9MJ7Uv++JCODCaFJJ2xmdXbM5/R9EH2qWyPzN7phNHgnNWh842Fj3maSGQQFm1K/+y0n3bM9jqHH6hsj4A7nfAzwALVAPHXF6zu3vj6Ak+DiQzAqm3ppjsWJr7odQ6/UNkeoXhL0zbgf3CODFYK0PbyI88m92x5w9NgIgexoS2z4cGVyY80Nic17ZUjKtshEG9pagZ+hTN/GwDY8/xvfp/ubt/maTCRfrR2247H16Q++t2FPTu9zuInKtuh8xzwFDARwPZ0JtpeeuRBm0roYOOSNxJpm5r/ZuqzNz/etdzrLH6jsh0i7sFqHgJeB8YBJHdt2NO+Yv7DOjOv5ANrLc+uS3/v6kfiWhDzgMp2CMVbmpLAT4A2oBage93S9V1vLZnraTARYPGmzJy7FyVu9TqHX6lsh1i8pakVZ8GsHIgAdLw6d3H3htXPeRpMfO3VLenFty/ouaaxOalPWR5R2WZBvKXpXeAeYAzOMXBpa/rtn3s2Nb/gaTDxpWWb0298d0HPRxqbk3Gvs/iZyjZL4i1NS3HmcCcAIYDWl2b/qWfrm02eBhNfWbE1/eadz/dc/sjqpLaM8ZjKNrvmAo/ibKEQBGh9/jfzEtvXL/E0lfjC6u3p9f++sOeK2a8l13idRVS2WeVuofAHoBGYxN5tcBfc/3hi21uLvMwmxW3F1vS6Oxb2fOLBVclVXmcRh8o2y9zCfRRnlFvH3sJd+Osneja3vORhNClSSzen1377uZ6rf70iuczrLPIelW0OxFuaMjhHCHsSp3CdKYUXH5zfvfH1hR5GkyLzysZU8+3P9Vz329VJTVXlGZVtjriF+yDwOM6UQhCg7eVHnul+e8XT1lov40kRWPB2atV3FiQ+9fs3kpqiykMq2xxyC/cR4DGcwg0BtC1+7PnO156dbdOphIfxpEClMjb9mxWJhd97MXFdY7OmDvKVyjbH3Dnc3+OU7kTcI4XFm59/o/XlR36RSXTt8TCeFJjOhI3/5wuJJ2a/lvq7xubkSq/zyIGpbD3gFu7jwM9xdnyoBkhsadm2+9lf/CzVvnO9h/GkQGzpyGyf9afuh17ekP5yY3Pyda/zyMGpbD0Sb2my8ZamBcAdOHuZjQJId+yK7/rTTx5IbFu32NOAktdWbk2/9dUnu3/8dqv9x8bm5Dqv88ihqWw9Fm9pagG+DWzHmVYwZNKZPQsfmBNf+8ocHTFMestYa59oSS679ZmeOzoS/Htjc3K315lkYFS2eSDe0rQduBNYhLNpWAigY/m8xe1L59xvUwnt0y4k0jbxk8XJZ36yODkL+L/G5mSP15lk4FS2eSLe0tQF/JT3Fs4iAN3rl729e8ED96Y6dr3tZT7x1taOzPZvPtvz2Ly1qa80NifnNzYnta1ggVHZ5pF4S1Mm3tL0OPB9nHOaDQdI7d7YuuvJH93X9daSeTpVur+kMzb95NrUki/M6f7la9szX2ls1u63hUplm4fiLU2v4szjduMcNSwA0L5sTtOeBQ/co1GuP2zrzGy57dmeOXcvSvw6meH2xubkZq8zyeFT2eYp95i438Q5t9kk3M3Dkjvf2a1RbnFLZ2x6/pupV25+vHvOym2ZHwA/bGxOdnidS45MyOsAcmDxlqY4cH+kvmExcBPOKHcjkGlfNqep+52Va6pOv+zyUGXtJE+DypDZ1pnZ8j8vJ15ZuS3zAnBfY7OOQ1ssjPbJLwyR+oYIcBVwIbAT5zxnAFSd+pGGsrrpF5pAMOxVvmy7tfsH62+qWVTndY5sSWds+ul16SU/WZxYmcrwa2CBTmFTXDSyLRCHHuWuWFN5yiUXhoaNO9EY42lWGZx1uzNrf7ok8drq7ZkX0Wi2aGlkW4AONsotHT91bMUJH7gwVD1yslf5sqEYR7ZbOjLv3r88ufT5d9Lbgd+g0WxRU9kWsEh9wwnA3+KcNn0rztYLAJQdPaOu4vhzLgpGasZ7lW8oFVPZ7uqy2363OvnyH9ek9gCvodGsL6hsC1ykvqEUeB9wJVAGbAH2Haoxcvy5UyOTz7gwUFYx3KOIQ6IYyrYjYVvnrEm9+OCq5LaMZRPO8Y1XaQcFf1DZFolIfUMFcAHwMZxN+jYDaQBMwFSefNGpZXXTPxAIl1V5l/LwFXLZdqds/Jl1qZf+b1lyYyLNTpyzdixubE6mvc4muaOyLTKR+oYa4EPAxUAKZ6SbATDh0lDFCedPLx0/dWawvGqUdykHrxDLtrXb7np5Q3rpAysSW9p6aAN+C7zQ2JzUQeJ9SGVbpCL1DaOAy4FzgC5gG7DvH7ts0rSJ5cecPjNUM3aqCQSCHsUcsEIp24y1dv0e2zz/zdTSuS2pLuu80TUCzzQ2J3VAIR9T2Ra5SH3DRJz53FNwphW2Avv2PAtWjaioOP7c00rG1J8eKCmr9ijmIeV72caTtuPVLemlD61Krl6/x5bilOyfgLmNzclWj+NJHlDZ+kSkvmEczkLaBTin4tkDvFcCJmAix551bNnEU2YGq0ZMzrdtdfO1bDe3Z9758/r0ot+uTu5IZigFdgFPAIsam5Nth7i7+IjK1mci9Q3lwKk487pHAT04By7ft1gTHjGptvzo004Mj5hwXKA8Oj4fijefynZnPLPljR2ZNU+9lVqzdHMmgLMg+SrwFNCshS/pj/Yg8xn3uLkvRuobXgKOAc4HzsQpjB1APLnj7V3JHW8vBBYGq0dWlteddmzJqLrjglUjjjGBoO9+Z9IZm97Ubtev3JZufvqt9JqWXZkAUIWzid184MXG5uR2b1NKvtPIVojUN0SBM3BGuzU4C2l7gPbetzMl5eHyo087pmTMlONC0THHBsKlFbnKmOuRbU/Kdq3bk2lZujndPG9t6q093USASvfb64C5wAptWSADpbKVfSL1DQGcqYUTgbPdv1ugE9iNuwnZXqUTTj6qdMzkumDVyHHBippxgZLyaLayZbtsOxO2fVun3fRuW2bT8i3pt59Zl96cttQCJTg/g9XAS8CaxubkjmzlkOLlu4+EcmDxlqYM8I57mRupbxgOHAecBUzFmWpI4CwCJXreXbmh592VG/beP1gxrLxkTP24cO24sbko4MPVu1hbdmY2L92c3vRum+3EORVRLWBwzpTxCrAEaNFmW3KkNLKVAXEPfjMFmAHMxBnxBXAW1jrcy34LQ3sLODRs7JhAWWV1oCRSFSgpqzThsioTKqkc6BzwYEa26YxNd6Xo6EzY9s4kHW09tn1Pt217c1dma69iDePMu+6dCjE4byIvACuB9Y3NydRAnk9kIFS2MmiR+oYgMAoYh3M24OPdPwM4pXXQAu4tEImWhapGVgUraqoCkWhloKyyKhAuK8cEAgHS5dHE9gkmMuztazJPdH6ibElFxpLJWDJpSzpjbSaepHtXl23fEbcdWzsy7e+22fatHbarz29132IF56A9a4E3gHdxdm/epeMUSLaobGVIHKKALU4J7x0JJ9xLj/tnv4VcRiJ6gll/Qa3p+P1BnjqEs91wSa8/cZ9z7/P2LdZNwG4Vq+SSylayxi3g4Tir+FXupRYY4V6G42z9EKbP4htACcmyk8y6E2pNx9J+Hn5vecdxPv7vwtl0bRvOzhodOFtTtAF7VKziNZWteCpS32BwRqRVvDcPHACCQOBEs758rNkVxynj3pc40NHYnNRJL6UgqGxFRHJApzIXEckBla2ISA6obEVEckBlKyKSAypbEZEcUNmKiOSAylZEJAdUtiIiOaCyFRHJAZWtiEgOqGxFRHJAZSsikgMqWxGRHFDZiojkgMpWRCQHVLYiIjmgshURyQGVrYhIDqhsRURyQGUrIpIDKlsRkRxQ2YqI5IDKVkQkB1S2IiI5oLIVEckBla2ISA6obEVEckBlKyKSAypbEZEcUNmKiOTA/weQXTh6VmB4dgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# declare a figure with a custom size\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "\n",
    "# labels for the two classes\n",
    "labels = \"Positives\", \"Negatives\"\n",
    "\n",
    "# sizes for each slide\n",
    "sizes = [len(all_positive_tweets), len(all_negative_tweets)]\n",
    "\n",
    "# declare pie chart where slices are ordered, and plotted counter clockwise\n",
    "plt.pie(sizes, labels= labels, autopct=\"%1.1f%%\", shadow=True, startangle=90)\n",
    "\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at raw texts\n",
    "Before anything else, we can print a couple of tweets from the dataset to see how they look. Understanding the data is responsible for 80% of the success or failure in data science projects. We can use this time to observe aspects we'd like to consider when preprocessing our data.\n",
    "\n",
    "Below, you will print one random positive and one random negative tweet. We have added a color mark at the beginning of the string to further distinguish the two. (Warning: This is taken from a public dataset of real tweets and a very small portion has explicit content.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m@SivaKaneswaran  Happy Birthday üéÇ  @JayMcGuiness  #Jiva for ever :) üçπüç∏üçª\n",
      "\u001b[91mAwww i thought it was today :( https://t.co/JK8xRlW6IF\n"
     ]
    }
   ],
   "source": [
    "# print positive in greeen\n",
    "print('\\033[92m' + all_positive_tweets[random.randint(0,5000)])\n",
    "\n",
    "# print negative in red\n",
    "print('\\033[91m' + all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One observation you may have is the presence of emoticons and URLs in many of the tweets. This info will come in handy in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess raw text for Sentiment analysis¬∂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n",
    "\n",
    "Tokenizing the string\n",
    "Lowercasing\n",
    "Removing stop words and punctuation\n",
    "Stemming\n",
    "The videos explained each of these steps and why they are important. Let's see how we can do these to a given tweet. We will choose just one and see how this is transformed by each preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n"
     ]
    }
   ],
   "source": [
    "# Our selected sample. Complex enough to exemplify each step\n",
    "tweet = all_positive_tweets[2277]\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import a few more libraries for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aryan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove hyperlinks, Twitter marks and styles\n",
    "Since we have a Twitter dataset, we'd like to remove some substrings commonly used on the platform like the hashtag, retweet marks, and hyperlinks. We'll use the re library to perform regular expression operations on our tweet. We'll define our search pattern and use the sub() method to remove matches by substituting with an empty character (i.e. '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mMy beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
      "\u001b[94m\n",
      "My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off‚Ä¶ \n"
     ]
    }
   ],
   "source": [
    "print('\\033[92m' + tweet)\n",
    "print('\\033[94m')\n",
    "\n",
    "# remove old style retweet text \"RT\"\n",
    "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "# remove hyperlinks\n",
    "tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
    "\n",
    "# remove hashtags\n",
    "# only removing the hash # sign from the word\n",
    "tweet2 = re.sub(r'#', '', tweet2)\n",
    "\n",
    "print(tweet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the string\n",
    "To tokenize means to split the strings into individual words without blanks or tabs. In this same step, we will also convert each word in the string to lower case. The tokenize module from NLTK allows us to do these easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mMy beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off‚Ä¶ \n",
      "\u001b[94m\n",
      "\n",
      "Tokenized string:\n",
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m' + tweet2)\n",
    "print('\\033[94m')\n",
    "\n",
    "# instantiate tokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "# tokenize tweets\n",
    "tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "\n",
    "print()\n",
    "print('Tokenized string:')\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words and punctuations\n",
    "The next step is to remove stop words and punctuation. Stop words are words that don't add significant meaning to the text. You'll see the list provided by NLTK when you run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words\n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Punctuation\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "print('Stop words\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the stop words list above contains some words that could be important in some contexts. These could be words like i, not, between, because, won, against. You might need to customize the stop words list for some applications. For our exercise, we will use the entire list.\n",
    "\n",
    "For the punctuation, we saw earlier that certain groupings like ':)' and '...' should be retained when dealing with tweets because they are used to express emotions. In other contexts, like medical analysis, these should also be removed.\n",
    "\n",
    "Time to clean up our tokenized tweet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '‚Ä¶']\n",
      "\u001b[94m\n",
      "removed stop words and punctuation:\n",
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweet_tokens)\n",
    "print('\\033[94m')\n",
    "\n",
    "tweets_clean = []\n",
    "\n",
    "for word in tweet_tokens: # Go through every word in your tokens list\n",
    "    if (word not in stopwords_english and  # remove stopwords\n",
    "        word not in string.punctuation):  # remove punctuation\n",
    "        tweets_clean.append(word)\n",
    "\n",
    "print('removed stop words and punctuation:')\n",
    "print(tweets_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the words happy and sunny in this list are correctly spelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of converting a word to its most general form, or stem. This helps in reducing the size of our vocabulary.\n",
    "\n",
    "Consider the words:\n",
    "\n",
    "learn\n",
    "learning\n",
    "learned\n",
    "learnt\n",
    "All these words are stemmed from its common root learn. However, in some cases, the stemming process produces words that are not correct spellings of the root word. For example, happi and sunni. That's because it chooses the most common stem for related words. For example, we can look at the set of words that comprises the different forms of happy:\n",
    "\n",
    "happy\n",
    "happiness\n",
    "happier\n",
    "We can see that the prefix happi is more commonly used. We cannot choose happ because it is the stem of unrelated words like happen.\n",
    "\n",
    "NLTK has different modules for stemming and we will be using the PorterStemmer module which uses the Porter Stemming Algorithm. Let's see how we can use it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '‚Ä¶']\n",
      "\u001b[94m\n",
      "stemmed words:\n",
      "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweets_clean)\n",
    "print('\\033[94m')\n",
    "\n",
    "# Instantiate stemming class\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# Create an empty list to store the stems\n",
    "tweets_stem = [] \n",
    "\n",
    "for word in tweets_clean:\n",
    "    stem_word = stemmer.stem(word)  # stemming word\n",
    "    tweets_stem.append(stem_word)  # append to the list\n",
    "\n",
    "print('stemmed words:')\n",
    "print(tweets_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now we have a set of words we can feed into to the next stage of our machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_tweet()\n",
    "As shown above, preprocessing consists of multiple steps before you arrive at the final list of words. We will not ask you to replicate these however.\n",
    "\n",
    "To obtain the same result as in the previous code cells, you will only need to call the function process_tweet(). Let's do that in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
      "\u001b[94m\n",
      "preprocessed tweet:\n",
      "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "# choose the same tweet\n",
    "tweet = all_positive_tweets[2277]\n",
    "\n",
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweet)\n",
    "print('\\033[94m')\n",
    "\n",
    "# call the imported function\n",
    "tweets_stem = process_tweet(tweet); # Preprocess a given tweet\n",
    "\n",
    "print('preprocessed tweet:')\n",
    "print(tweets_stem) # Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
